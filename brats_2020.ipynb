{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ],
      "metadata": {
        "id": "VpGy2cxZ1wk1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jiGRXU8KbvS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import glob\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJoQOHePYnVz",
        "outputId": "7a9d36af-d7be-4dc3-ce0b-f205b0aabad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n"
      ],
      "metadata": {
        "id": "foWeWUXCehlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "SclExdVRCJUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2_list = sorted(glob.glob('/content/drive/MyDrive/BraTS2020_Extracted/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t2.nii'))\n",
        "t1ce_list = sorted(glob.glob('/content/drive/MyDrive/BraTS2020_Extracted/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t1ce.nii'))\n",
        "flair_list = sorted(glob.glob('/content/drive/MyDrive/BraTS2020_Extracted/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*flair.nii'))\n",
        "mask_list = sorted(glob.glob('/content/drive/MyDrive/BraTS2020_Extracted/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*seg.nii'))"
      ],
      "metadata": {
        "id": "CWhX6U3L9m4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/BraTS2020_Extracted/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
        "save_dir = '/content/drive/MyDrive/BraTS2020_Extracted/BraTS2020_TrainingData/processed_data'\n",
        "\n",
        "\n",
        "os.makedirs(f'{save_dir}/images', exist_ok=True)\n",
        "os.makedirs(f'{save_dir}/masks', exist_ok=True)\n",
        "\n",
        "\n",
        "cases = sorted(glob(f'{data_dir}/*'))\n",
        "t2_list = [f'{c}/{os.path.basename(c)}_t2.nii' for c in cases]\n",
        "t1ce_list = [f'{c}/{os.path.basename(c)}_t1ce.nii' for c in cases]\n",
        "flair_list = [f'{c}/{os.path.basename(c)}_flair.nii' for c in cases]\n",
        "mask_list = [f'{c}/{os.path.basename(c)}_seg.nii' for c in cases]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# First pass: Computing dataset statistics\n",
        "print(\"Calculating dataset statistics...\")\n",
        "for i in range(len(t2_list)):\n",
        "    t2_data = nib.load(t2_list[i]).get_fdata().reshape(-1, 1)\n",
        "\n",
        "    # T1CE\n",
        "    t1ce_data = nib.load(t1ce_list[i]).get_fdata().reshape(-1, 1)\n",
        "\n",
        "\n",
        "    # FLAIR\n",
        "    flair_data = nib.load(flair_list[i]).get_fdata().reshape(-1, 1)\n",
        "\n",
        "\n",
        "# Second pass: Processing and save data\n",
        "print(\"\\nProcessing and saving data...\")\n",
        "for idx in range(len(t2_list)):\n",
        "    print(f\"Processing case {idx+1}/{len(t2_list)}\")\n",
        "\n",
        "    # Loading raw data\n",
        "    t2 = nib.load(t2_list[idx]).get_fdata()\n",
        "    t1ce = nib.load(t1ce_list[idx]).get_fdata()\n",
        "    flair = nib.load(flair_list[idx]).get_fdata()\n",
        "    mask = nib.load(mask_list[idx]).get_fdata()\n",
        "\n",
        "    # Normalizing using dataset statistics\n",
        "    t2 = scaler_t2.transform(t2.reshape(-1, 1)).reshape(t2.shape)\n",
        "    t1ce = scaler_t1ce.transform(t1ce.reshape(-1, 1)).reshape(t1ce.shape)\n",
        "    flair = scaler_flair.transform(flair.reshape(-1, 1)).reshape(flair.shape)\n",
        "\n",
        "\n",
        "    mask = mask.astype(np.uint8)\n",
        "    mask[mask == 4] = 3\n",
        "\n",
        "\n",
        "    combined = np.stack([flair, t1ce, t2], axis=-1)[56:184, 56:184, 13:141]\n",
        "    mask_cropped = mask[56:184, 56:184, 13:141]\n",
        "\n",
        "    np.save(f'{save_dir}/images/case_{idx}.npy', combined)\n",
        "    np.save(f'{save_dir}/masks/case_{idx}.npy', mask_cropped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZSUZrKbwTj7",
        "outputId": "af39afbf-1a6c-4cf4-87ff-c503834f67c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating dataset statistics...\n",
            "\n",
            "Processing and saving data...\n",
            "Processing case 1/369\n",
            "Processing case 2/369\n",
            "Processing case 3/369\n",
            "Processing case 4/369\n",
            "Processing case 5/369\n",
            "Processing case 6/369\n",
            "Processing case 7/369\n",
            "Processing case 8/369\n",
            "Processing case 9/369\n",
            "Processing case 10/369\n",
            "Processing case 11/369\n",
            "Processing case 12/369\n",
            "Processing case 13/369\n",
            "Processing case 14/369\n",
            "Processing case 15/369\n",
            "Processing case 16/369\n",
            "Processing case 17/369\n",
            "Processing case 18/369\n",
            "Processing case 19/369\n",
            "Processing case 20/369\n",
            "Processing case 21/369\n",
            "Processing case 22/369\n",
            "Processing case 23/369\n",
            "Processing case 24/369\n",
            "Processing case 25/369\n",
            "Processing case 26/369\n",
            "Processing case 27/369\n",
            "Processing case 28/369\n",
            "Processing case 29/369\n",
            "Processing case 30/369\n",
            "Processing case 31/369\n",
            "Processing case 32/369\n",
            "Processing case 33/369\n",
            "Processing case 34/369\n",
            "Processing case 35/369\n",
            "Processing case 36/369\n",
            "Processing case 37/369\n",
            "Processing case 38/369\n",
            "Processing case 39/369\n",
            "Processing case 40/369\n",
            "Processing case 41/369\n",
            "Processing case 42/369\n",
            "Processing case 43/369\n",
            "Processing case 44/369\n",
            "Processing case 45/369\n",
            "Processing case 46/369\n",
            "Processing case 47/369\n",
            "Processing case 48/369\n",
            "Processing case 49/369\n",
            "Processing case 50/369\n",
            "Processing case 51/369\n",
            "Processing case 52/369\n",
            "Processing case 53/369\n",
            "Processing case 54/369\n",
            "Processing case 55/369\n",
            "Processing case 56/369\n",
            "Processing case 57/369\n",
            "Processing case 58/369\n",
            "Processing case 59/369\n",
            "Processing case 60/369\n",
            "Processing case 61/369\n",
            "Processing case 62/369\n",
            "Processing case 63/369\n",
            "Processing case 64/369\n",
            "Processing case 65/369\n",
            "Processing case 66/369\n",
            "Processing case 67/369\n",
            "Processing case 68/369\n",
            "Processing case 69/369\n",
            "Processing case 70/369\n",
            "Processing case 71/369\n",
            "Processing case 72/369\n",
            "Processing case 73/369\n",
            "Processing case 74/369\n",
            "Processing case 75/369\n",
            "Processing case 76/369\n",
            "Processing case 77/369\n",
            "Processing case 78/369\n",
            "Processing case 79/369\n",
            "Processing case 80/369\n",
            "Processing case 81/369\n",
            "Processing case 82/369\n",
            "Processing case 83/369\n",
            "Processing case 84/369\n",
            "Processing case 85/369\n",
            "Processing case 86/369\n",
            "Processing case 87/369\n",
            "Processing case 88/369\n",
            "Processing case 89/369\n",
            "Processing case 90/369\n",
            "Processing case 91/369\n",
            "Processing case 92/369\n",
            "Processing case 93/369\n",
            "Processing case 94/369\n",
            "Processing case 95/369\n",
            "Processing case 96/369\n",
            "Processing case 97/369\n",
            "Processing case 98/369\n",
            "Processing case 99/369\n",
            "Processing case 100/369\n",
            "Processing case 101/369\n",
            "Processing case 102/369\n",
            "Processing case 103/369\n",
            "Processing case 104/369\n",
            "Processing case 105/369\n",
            "Processing case 106/369\n",
            "Processing case 107/369\n",
            "Processing case 108/369\n",
            "Processing case 109/369\n",
            "Processing case 110/369\n",
            "Processing case 111/369\n",
            "Processing case 112/369\n",
            "Processing case 113/369\n",
            "Processing case 114/369\n",
            "Processing case 115/369\n",
            "Processing case 116/369\n",
            "Processing case 117/369\n",
            "Processing case 118/369\n",
            "Processing case 119/369\n",
            "Processing case 120/369\n",
            "Processing case 121/369\n",
            "Processing case 122/369\n",
            "Processing case 123/369\n",
            "Processing case 124/369\n",
            "Processing case 125/369\n",
            "Processing case 126/369\n",
            "Processing case 127/369\n",
            "Processing case 128/369\n",
            "Processing case 129/369\n",
            "Processing case 130/369\n",
            "Processing case 131/369\n",
            "Processing case 132/369\n",
            "Processing case 133/369\n",
            "Processing case 134/369\n",
            "Processing case 135/369\n",
            "Processing case 136/369\n",
            "Processing case 137/369\n",
            "Processing case 138/369\n",
            "Processing case 139/369\n",
            "Processing case 140/369\n",
            "Processing case 141/369\n",
            "Processing case 142/369\n",
            "Processing case 143/369\n",
            "Processing case 144/369\n",
            "Processing case 145/369\n",
            "Processing case 146/369\n",
            "Processing case 147/369\n",
            "Processing case 148/369\n",
            "Processing case 149/369\n",
            "Processing case 150/369\n",
            "Processing case 151/369\n",
            "Processing case 152/369\n",
            "Processing case 153/369\n",
            "Processing case 154/369\n",
            "Processing case 155/369\n",
            "Processing case 156/369\n",
            "Processing case 157/369\n",
            "Processing case 158/369\n",
            "Processing case 159/369\n",
            "Processing case 160/369\n",
            "Processing case 161/369\n",
            "Processing case 162/369\n",
            "Processing case 163/369\n",
            "Processing case 164/369\n",
            "Processing case 165/369\n",
            "Processing case 166/369\n",
            "Processing case 167/369\n",
            "Processing case 168/369\n",
            "Processing case 169/369\n",
            "Processing case 170/369\n",
            "Processing case 171/369\n",
            "Processing case 172/369\n",
            "Processing case 173/369\n",
            "Processing case 174/369\n",
            "Processing case 175/369\n",
            "Processing case 176/369\n",
            "Processing case 177/369\n",
            "Processing case 178/369\n",
            "Processing case 179/369\n",
            "Processing case 180/369\n",
            "Processing case 181/369\n",
            "Processing case 182/369\n",
            "Processing case 183/369\n",
            "Processing case 184/369\n",
            "Processing case 185/369\n",
            "Processing case 186/369\n",
            "Processing case 187/369\n",
            "Processing case 188/369\n",
            "Processing case 189/369\n",
            "Processing case 190/369\n",
            "Processing case 191/369\n",
            "Processing case 192/369\n",
            "Processing case 193/369\n",
            "Processing case 194/369\n",
            "Processing case 195/369\n",
            "Processing case 196/369\n",
            "Processing case 197/369\n",
            "Processing case 198/369\n",
            "Processing case 199/369\n",
            "Processing case 200/369\n",
            "Processing case 201/369\n",
            "Processing case 202/369\n",
            "Processing case 203/369\n",
            "Processing case 204/369\n",
            "Processing case 205/369\n",
            "Processing case 206/369\n",
            "Processing case 207/369\n",
            "Processing case 208/369\n",
            "Processing case 209/369\n",
            "Processing case 210/369\n",
            "Processing case 211/369\n",
            "Processing case 212/369\n",
            "Processing case 213/369\n",
            "Processing case 214/369\n",
            "Processing case 215/369\n",
            "Processing case 216/369\n",
            "Processing case 217/369\n",
            "Processing case 218/369\n",
            "Processing case 219/369\n",
            "Processing case 220/369\n",
            "Processing case 221/369\n",
            "Processing case 222/369\n",
            "Processing case 223/369\n",
            "Processing case 224/369\n",
            "Processing case 225/369\n",
            "Processing case 226/369\n",
            "Processing case 227/369\n",
            "Processing case 228/369\n",
            "Processing case 229/369\n",
            "Processing case 230/369\n",
            "Processing case 231/369\n",
            "Processing case 232/369\n",
            "Processing case 233/369\n",
            "Processing case 234/369\n",
            "Processing case 235/369\n",
            "Processing case 236/369\n",
            "Processing case 237/369\n",
            "Processing case 238/369\n",
            "Processing case 239/369\n",
            "Processing case 240/369\n",
            "Processing case 241/369\n",
            "Processing case 242/369\n",
            "Processing case 243/369\n",
            "Processing case 244/369\n",
            "Processing case 245/369\n",
            "Processing case 246/369\n",
            "Processing case 247/369\n",
            "Processing case 248/369\n",
            "Processing case 249/369\n",
            "Processing case 250/369\n",
            "Processing case 251/369\n",
            "Processing case 252/369\n",
            "Processing case 253/369\n",
            "Processing case 254/369\n",
            "Processing case 255/369\n",
            "Processing case 256/369\n",
            "Processing case 257/369\n",
            "Processing case 258/369\n",
            "Processing case 259/369\n",
            "Processing case 260/369\n",
            "Processing case 261/369\n",
            "Processing case 262/369\n",
            "Processing case 263/369\n",
            "Processing case 264/369\n",
            "Processing case 265/369\n",
            "Processing case 266/369\n",
            "Processing case 267/369\n",
            "Processing case 268/369\n",
            "Processing case 269/369\n",
            "Processing case 270/369\n",
            "Processing case 271/369\n",
            "Processing case 272/369\n",
            "Processing case 273/369\n",
            "Processing case 274/369\n",
            "Processing case 275/369\n",
            "Processing case 276/369\n",
            "Processing case 277/369\n",
            "Processing case 278/369\n",
            "Processing case 279/369\n",
            "Processing case 280/369\n",
            "Processing case 281/369\n",
            "Processing case 282/369\n",
            "Processing case 283/369\n",
            "Processing case 284/369\n",
            "Processing case 285/369\n",
            "Processing case 286/369\n",
            "Processing case 287/369\n",
            "Processing case 288/369\n",
            "Processing case 289/369\n",
            "Processing case 290/369\n",
            "Processing case 291/369\n",
            "Processing case 292/369\n",
            "Processing case 293/369\n",
            "Processing case 294/369\n",
            "Processing case 295/369\n",
            "Processing case 296/369\n",
            "Processing case 297/369\n",
            "Processing case 298/369\n",
            "Processing case 299/369\n",
            "Processing case 300/369\n",
            "Processing case 301/369\n",
            "Processing case 302/369\n",
            "Processing case 303/369\n",
            "Processing case 304/369\n",
            "Processing case 305/369\n",
            "Processing case 306/369\n",
            "Processing case 307/369\n",
            "Processing case 308/369\n",
            "Processing case 309/369\n",
            "Processing case 310/369\n",
            "Processing case 311/369\n",
            "Processing case 312/369\n",
            "Processing case 313/369\n",
            "Processing case 314/369\n",
            "Processing case 315/369\n",
            "Processing case 316/369\n",
            "Processing case 317/369\n",
            "Processing case 318/369\n",
            "Processing case 319/369\n",
            "Processing case 320/369\n",
            "Processing case 321/369\n",
            "Processing case 322/369\n",
            "Processing case 323/369\n",
            "Processing case 324/369\n",
            "Processing case 325/369\n",
            "Processing case 326/369\n",
            "Processing case 327/369\n",
            "Processing case 328/369\n",
            "Processing case 329/369\n",
            "Processing case 330/369\n",
            "Processing case 331/369\n",
            "Processing case 332/369\n",
            "Processing case 333/369\n",
            "Processing case 334/369\n",
            "Processing case 335/369\n",
            "Processing case 336/369\n",
            "Processing case 337/369\n",
            "Processing case 338/369\n",
            "Processing case 339/369\n",
            "Processing case 340/369\n",
            "Processing case 341/369\n",
            "Processing case 342/369\n",
            "Processing case 343/369\n",
            "Processing case 344/369\n",
            "Processing case 345/369\n",
            "Processing case 346/369\n",
            "Processing case 347/369\n",
            "Processing case 348/369\n",
            "Processing case 349/369\n",
            "Processing case 350/369\n",
            "Processing case 351/369\n",
            "Processing case 352/369\n",
            "Processing case 353/369\n",
            "Processing case 354/369\n",
            "Processing case 355/369\n",
            "Processing case 356/369\n",
            "Processing case 357/369\n",
            "Processing case 358/369\n",
            "Processing case 359/369\n",
            "Processing case 360/369\n",
            "Processing case 361/369\n",
            "Processing case 362/369\n",
            "Processing case 363/369\n",
            "Processing case 364/369\n",
            "Processing case 365/369\n",
            "Processing case 366/369\n",
            "Processing case 367/369\n",
            "Processing case 368/369\n",
            "Processing case 369/369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code for Simple U-Net"
      ],
      "metadata": {
        "id": "ji3ZnJNauyhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_classes=4, init_channels=32):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = self._block(in_channels, init_channels)\n",
        "        self.pool1 = nn.MaxPool3d(2, 2)\n",
        "        self.enc2 = self._block(init_channels, init_channels*2)\n",
        "        self.pool2 = nn.MaxPool3d(2, 2)\n",
        "        self.enc3 = self._block(init_channels*2, init_channels*4)\n",
        "        self.pool3 = nn.MaxPool3d(2, 2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self._block(init_channels*4, init_channels*8)\n",
        "\n",
        "        # Decoder\n",
        "        self.up3 = nn.ConvTranspose3d(init_channels*8, init_channels*4, kernel_size=2, stride=2)\n",
        "        self.dec3 = self._block(init_channels*8, init_channels*4)\n",
        "        self.up2 = nn.ConvTranspose3d(init_channels*4, init_channels*2, kernel_size=2, stride=2)\n",
        "        self.dec2 = self._block(init_channels*4, init_channels*2)\n",
        "        self.up1 = nn.ConvTranspose3d(init_channels*2, init_channels, kernel_size=2, stride=2)\n",
        "        self.dec1 = self._block(init_channels*2, init_channels)\n",
        "\n",
        "        self.final_conv = nn.Conv3d(init_channels, out_classes, kernel_size=1)\n",
        "\n",
        "    def _block(self, in_channels, features):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv3d(in_channels, features, 3, padding=1),\n",
        "            nn.GroupNorm(8, features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(features, features, 3, padding=1),\n",
        "            nn.GroupNorm(8, features),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        enc1 = self.enc1(x)\n",
        "        pool1 = self.pool1(enc1)\n",
        "        enc2 = self.enc2(pool1)\n",
        "        pool2 = self.pool2(enc2)\n",
        "        enc3 = self.enc3(pool2)\n",
        "        pool3 = self.pool3(enc3)\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck = self.bottleneck(pool3)\n",
        "\n",
        "        # Decoder\n",
        "        up3 = self.up3(bottleneck)\n",
        "        dec3 = self.dec3(torch.cat([up3, enc3], 1))\n",
        "        up2 = self.up2(dec3)\n",
        "        dec2 = self.dec2(torch.cat([up2, enc2], 1))\n",
        "        up1 = self.up1(dec2)\n",
        "        dec1 = self.dec1(torch.cat([up1, enc1], 1))\n",
        "\n",
        "        return self.final_conv(dec1)"
      ],
      "metadata": {
        "id": "l0S0hWhXujan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code For Attention U-Net"
      ],
      "metadata": {
        "id": "FOVcEcXtulLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionUNet(UNet):\n",
        "    class AttentionGate(nn.Module):\n",
        "        def __init__(self, in_channels, inter_channels):\n",
        "            super().__init__()\n",
        "            self.W_g = nn.Conv3d(in_channels, 1)\n",
        "            self.W_x = nn.Conv3d(in_channels, 1)\n",
        "            self.sigmoid = nn.Sigmoid()\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        def forward(self, g, x):\n",
        "            g1 = self.W_g(g)\n",
        "            x1 = self.W_x(x)\n",
        "            psi = self.relu(g1 + x1)\n",
        "            psi = self.sigmoid(self.psi(psi))\n",
        "            return x * psi\n",
        "\n",
        "    def __init__(self, in_channels=3, out_classes=4, init_channels=32):\n",
        "        super().__init__(in_channels, out_classes, init_channels)\n",
        "\n",
        "\n",
        "        self.up3 = nn.ConvTranspose3d(init_channels*8, init_channels*4, 2, 2)\n",
        "        self.att3 = self.AttentionGate(init_channels*4, init_channels*4//2)\n",
        "        self.up2 = nn.ConvTranspose3d(init_channels*4, init_channels*2, 2, 2)\n",
        "        self.att2 = self.AttentionGate(init_channels*2, init_channels*2//2)\n",
        "        self.up1 = nn.ConvTranspose3d(init_channels*2, init_channels, 2, 2)\n",
        "        self.att1 = self.AttentionGate(init_channels, init_channels//2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        enc1 = self.enc1(x)\n",
        "        pool1 = self.pool1(enc1)\n",
        "        enc2 = self.enc2(pool1)\n",
        "        pool2 = self.pool2(enc2)\n",
        "        enc3 = self.enc3(pool2)\n",
        "        pool3 = self.pool3(enc3)\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck = self.bottleneck(pool3)\n",
        "\n",
        "        # Decoder with attention\n",
        "        up3 = self.up3(bottleneck)\n",
        "        att3 = self.att3(up3, enc3)\n",
        "        dec3 = self.dec3(torch.cat([up3, att3], 1))\n",
        "\n",
        "        up2 = self.up2(dec3)\n",
        "        att2 = self.att2(up2, enc2)\n",
        "        dec2 = self.dec2(torch.cat([up2, att2], 1))\n",
        "\n",
        "        up1 = self.up1(dec2)\n",
        "        att1 = self.att1(up1, enc1)\n",
        "        dec1 = self.dec1(torch.cat([up1, att1], 1))\n",
        "\n",
        "        return self.final_conv(dec1)"
      ],
      "metadata": {
        "id": "FZbY1sxBAc_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BraTSDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir):\n",
        "        self.image_paths = sorted(glob(os.path.join(image_dir, \"*.npy\")))\n",
        "        self.mask_paths = sorted(glob(os.path.join(mask_dir, \"*.npy\")))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.load(self.image_paths[idx])\n",
        "        mask = np.load(self.mask_paths[idx])\n",
        "\n",
        "        # Converting to PyTorch format and permute dimensions because PyTorch requires data in this format\n",
        "        image = torch.tensor(image).float().permute(3, 2, 0, 1)\n",
        "        mask = torch.tensor(mask).long()\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "l7hmyT2idVfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Centralised Learning"
      ],
      "metadata": {
        "id": "s0znK6kt3eCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_centralized_model(num_epochs=2):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    base_dir = \"/content/drive/MyDrive/BraTS2020_Extracted/BraTS2020_TrainingData/fed\"\n",
        "\n",
        "    # Creating combined dataset from all hospitals\n",
        "    combined_dataset = ConcatDataset([\n",
        "        BraTSDataset(\n",
        "            os.path.join(base_dir, f\"hosp{i}/images\"),\n",
        "            os.path.join(base_dir, f\"hosp{i}/masks\")\n",
        "        ) for i in range(1, 6)\n",
        "    ])\n",
        "\n",
        "    train_loader = DataLoader(combined_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "\n",
        "    model = UNet().to(device)\n",
        "\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, masks in train_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    return model.state_dict()\n"
      ],
      "metadata": {
        "id": "9Slokzve3g0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Federated Learning"
      ],
      "metadata": {
        "id": "JJkK2ePn7hjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_client_model(client_id, global_weights, num_epochs=2):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Loading client data\n",
        "    base_dir = \"/content/drive/MyDrive/BraTS2020_Extracted/BraTS2020_TrainingData/fed\"\n",
        "    train_dataset = BraTSDataset(\n",
        "        os.path.join(base_dir, f\"hosp{client_id}/images\"),\n",
        "        os.path.join(base_dir, f\"hosp{client_id}/masks\")\n",
        "    )\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "    # Initialize model\n",
        "    model = UNet().to(device)\n",
        "    model.load_state_dict(global_weights)\n",
        "\n",
        "\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, masks in train_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Cleanup\n",
        "    del images, masks, outputs\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return model.state_dict()\n",
        "\n",
        "def federated_average(client_weights_list):\n",
        "    avg_weights = {}\n",
        "    for key in client_weights_list[0].keys():\n",
        "        avg_weights[key] = torch.mean(\n",
        "            torch.stack([client_weights[key] for client_weights in client_weights_list]),\n",
        "            dim=0\n",
        "        )\n",
        "    return avg_weights"
      ],
      "metadata": {
        "id": "NNqS7M8edX-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coeff(pred, target, smooth=1e-6):\n",
        "\n",
        "    if pred.dim() == target.dim() + 1:\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "\n",
        "\n",
        "    num_classes = pred.max().item() + 1\n",
        "    target_one_hot = torch.nn.functional.one_hot(target, num_classes).permute(0, 4, 1, 2, 3).float()\n",
        "    pred_one_hot = torch.nn.functional.one_hot(pred, num_classes).permute(0, 4, 1, 2, 3).float()\n",
        "\n",
        "    # Calculating intersection and union\n",
        "    intersection = (pred_one_hot * target_one_hot).sum(dim=(0, 1, 2, 3))\n",
        "    union = pred_one_hot.sum(dim=(0, 1, 2, 3)) + target_one_hot.sum(dim=(0, 1, 2, 3))\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return dice.mean().item()\n",
        "\n",
        "def jaccard_similarity(pred, target, smooth=1e-6):\n",
        "\n",
        "    if pred.dim() == target.dim() + 1:\n",
        "        pred = torch.argmax(pred, dim=1)\n",
        "\n",
        "    num_classes = pred.max().item() + 1\n",
        "    target_one_hot = torch.nn.functional.one_hot(target, num_classes).permute(0, 4, 1, 2, 3).float()\n",
        "    pred_one_hot = torch.nn.functional.one_hot(pred, num_classes).permute(0, 4, 1, 2, 3).float()\n",
        "\n",
        "    intersection = (pred_one_hot * target_one_hot).sum(dim=(0, 1, 2, 3))\n",
        "    union = pred_one_hot.sum(dim=(0, 2, 3, 4)) + target_one_hot.sum(dim=(0, 1, 2, 3)) - intersection\n",
        "\n",
        "    jaccard = (intersection + smooth) / (union + smooth)\n",
        "    return jaccard.mean().item()\n"
      ],
      "metadata": {
        "id": "4Ybv4j0PVYy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_global_model(model, val_dir):\n",
        "    val_dataset = BraTSDataset(\n",
        "        os.path.join(val_dir, \"images\"),\n",
        "        os.path.join(val_dir, \"masks\")\n",
        "    )\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1)\n",
        "\n",
        "    model.eval()\n",
        "    total_dice = 0.0\n",
        "    total_jaccard = 0.0\n",
        "    class_dice = {1: 0.0, 2: 0.0, 3: 0.0}\n",
        "    class_counts = {1: 1e-6, 2: 1e-6, 3: 1e-6}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images, masks = images.cuda(), masks.cuda()\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Convert logits to class predictions\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "\n",
        "            for cls in [1, 2, 3]:\n",
        "                pred_cls = (preds == cls)\n",
        "                mask_cls = (masks == cls)\n",
        "\n",
        "                if mask_cls.sum() > 0:\n",
        "                    dice = dice_coefficient(pred_cls.float(), mask_cls.float())\n",
        "                    jaccard = jaccard_similarity(pred_cls.float(), mask_cls.float())\n",
        "\n",
        "                    class_dice[cls] += dice\n",
        "                    class_counts[cls] += 1\n",
        "\n",
        "            # Calculating combined regions\n",
        "            wt_pred = (preds >= 1)  # Whole Tumor: 1+2+3\n",
        "            wt_mask = (masks >= 1)\n",
        "            total_dice += dice_coefficient(wt_pred.float(), wt_mask.float())\n",
        "\n",
        "            tc_pred = (preds == 1) | (preds == 3)  # Tumor Core: 1+3\n",
        "            tc_mask = (masks == 1) | (masks == 3)\n",
        "            total_jaccard += jaccard_similarity(tc_pred.float(), tc_mask.float())\n",
        "\n",
        "    # Average metrics\n",
        "    metrics = {\n",
        "        'mean_dice': total_dice / len(val_loader),\n",
        "        'mean_jaccard': total_jaccard / len(val_loader),\n",
        "        'class_dice': {cls: class_dice[cls]/class_counts[cls] for cls in [1, 2, 3]}\n",
        "    }\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "yfKDv9dLdbPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_model = UNet().cuda()\n",
        "global_weights = global_model.state_dict()\n",
        "\n",
        "    # Federated parameters\n",
        "num_clients = 5\n",
        "num_rounds = 2\n",
        "val_dir = \"/content/drive/MyDrive/BraTS2020_Extracted/BraTS2020_TrainingData/val\"\n",
        "\n",
        "    # Training loop\n",
        "for round in range(num_rounds):\n",
        "        print(f\"\\n--- Round {round+1}/{num_rounds} ---\")\n",
        "\n",
        "        # Client training\n",
        "        client_weights = []\n",
        "        for client_id in range(1, num_clients+1):\n",
        "            print(f\"Training client {client_id}...\")\n",
        "            client_weights.append(train_client_model(client_id, global_weights))\n",
        "\n",
        "        # Aggregating weights\n",
        "        global_weights = federated_average(client_weights)\n",
        "        global_model.load_state_dict(global_weights)\n",
        "\n",
        "        # Validation\n",
        "        val_dice = evaluate_global_model(global_model, val_dir)\n",
        "        print(f\"Validation Dice: {val_dice:.4f}\")\n",
        "\n",
        "        # Saving model\n",
        "        torch.save(global_weights, f\"global_model_round_{round}.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmzJGpmLdeTw",
        "outputId": "70d09426-bd84-4c1c-df9b-b61a67431130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Round 1/2 ===\n",
            "Training Client 1...\n",
            "Training Client 2...\n",
            "Training Client 3...\n",
            "Training Client 4...\n",
            "Training Client 5...\n",
            "\n",
            "=== Round 2/2 ===\n",
            "Training Client 1...\n",
            "Training Client 2...\n",
            "Training Client 3...\n",
            "Training Client 4...\n",
            "Training Client 5...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = evaluate_global_model(model, val_loader)\n",
        "print(f\"Mean Dice: {metrics['mean_dice']:.}\")\n",
        "print(f\"Mean Jaccard: {metrics['mean_jaccard']:.4f}\")\n",
        "print(f\"Class-wise Dice:\")\n",
        "print(f\"  Whole Tumor (1+2+3): {metrics['class_dice'][1]:.4f}\")\n",
        "print(f\"  Tumor Core (1+3): {metrics['class_dice'][2]:.4f}\")\n",
        "print(f\"  Enhancing Tumor (3): {metrics['class_dice'][3]:.4f}\")"
      ],
      "metadata": {
        "id": "Apjd1VC2EMIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bfb5bc-0c7e-478a-d958-16918daf80d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Dice: 0.3407\n",
            "Mean Jaccard: 0.2698\n",
            "Class-wise Dice:\n",
            "  Whole Tumor (1+2+3): 0.4622\n",
            "  Tumor Core (1+3): 0.3345\n",
            "  Enhancing Tumor (3): 0.2254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKE96vCH8r6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}